Okay, ich erkl√§re es Schritt f√ºr Schritt, damit du es einfach nachmachen kannst. üöÄ  

---

## **1Ô∏è‚É£ Kamera einrichten üé•**  
### **Welche Kamera brauchst du?**  
- Wenn die Kamera **weit weg vom PC** ist ‚Üí **IP-Kamera** (z. B. Reolink RLC-520A)  
- Wenn die Kamera **nah am PC** ist ‚Üí **USB-Kamera** (z. B. Logitech C920)  

### **So richtest du die Kamera ein:**  
**USB-Kamera:** Einfach per USB anstecken ‚Äì fertig!  
**IP-Kamera:**  
- Kamera mit Strom & Netzwerk verbinden (PoE oder WLAN)  
- Im Webbrowser die IP-Adresse der Kamera eingeben  
- Einstellungen vornehmen (Aufl√∂sung, Stream aktivieren)  

---

## **2Ô∏è‚É£ Computer vorbereiten üíª**  
Du brauchst einen PC oder Mini-PC (z. B. Intel NUC, Raspberry Pi geht auch f√ºr einfachere Anwendungen).  

**Software installieren (auf Linux oder Windows):**  
1. Installiere Python (falls noch nicht vorhanden)  
2. Installiere die ben√∂tigten Pakete:  
   ```bash
   pip install opencv-python ultralytics
   ```
3. Teste, ob die Kamera erkannt wird:  
   ```python
   import cv2
   cap = cv2.VideoCapture(0)  # F√ºr USB-Kamera
   while True:
       ret, frame = cap.read()
       if not ret:
           break
       cv2.imshow("Kamera", frame)
       if cv2.waitKey(1) & 0xFF == ord('q'):
           break
   cap.release()
   cv2.destroyAllWindows()
   ```
   - Falls du eine **IP-Kamera** nutzt, ersetze `0` durch die RTSP-URL der Kamera.  
     Beispiel:  
     ```python
     cap = cv2.VideoCapture("rtsp://benutzer:passwort@ip-adresse:554/stream")
     ```

---

## **3Ô∏è‚É£ KI-Modell f√ºr Objekterkennung üß†**  
Wir nutzen **YOLOv8**, ein fertiges Modell zur Objekterkennung.  

### **YOLO-Modell herunterladen:**  
```bash
pip install ultralytics
```

### **Objekterkennung starten:**  
```python
from ultralytics import YOLO
import cv2

# Modell laden
model = YOLO("yolov8n.pt")  # Fertiges Modell f√ºr Objekterkennung

# Kamera-Stream starten
cap = cv2.VideoCapture(0)  # USB-Kamera (f√ºr IP-Kamera RTSP-Link einf√ºgen)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # YOLO-Detektion
    results = model(frame)

    # Ergebnisse zeichnen
    for result in results:
        frame = result.plot()

    cv2.imshow("Erkennung", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
```

Wenn du das startest, erkennt das Programm Autos üöó, Fahrr√§der üö≤ und Fu√üg√§nger üö∂‚Äç‚ôÇÔ∏è in Echtzeit! üéâ  

---

## **4Ô∏è‚É£ Erkennung speichern (14 Tage) üíæ**  
### **Speicherung der Videos:**  
```python
import datetime
import os

# Speicherordner
save_path = "videos"
os.makedirs(save_path, exist_ok=True)

# Video-Writer
fourcc = cv2.VideoWriter_fourcc(*'XVID')
now = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
out = cv2.VideoWriter(f"{save_path}/{now}.avi", fourcc, 20.0, (640, 480))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame)
    frame = results[0].plot()

    out.write(frame)  # Video speichern

    cv2.imshow("Erkennung", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
out.release()
cv2.destroyAllWindows()
```

### **Alte Videos nach 14 Tagen l√∂schen:**  
Erstelle ein Skript `cleanup.py`:  
```python
import os
import time

folder = "videos"
days = 14
now = time.time()

for file in os.listdir(folder):
    filepath = os.path.join(folder, file)
    if os.stat(filepath).st_mtime < now - days * 86400:
        os.remove(filepath)
        print(f"Gel√∂scht: {filepath}")
```
Lass das Skript per **Cronjob (Linux)** oder **Geplante Aufgaben (Windows)** jeden Tag laufen.  

---

## **5Ô∏è‚É£ Ampelsteuerung üö¶**  
Falls du eine Ampel steuern willst, kannst du einen **ESP32 oder Raspberry Pi** verwenden. Der PC schickt ein Signal, wenn ein Auto erkannt wird.  

Beispiel:  
```python
import paho.mqtt.client as mqtt

mqtt_broker = "192.168.1.100"  # IP des ESP32/Raspberry Pi
client = mqtt.Client()
client.connect(mqtt_broker)

while True:
    ret, frame = cap.read()
    results = model(frame)

    # Falls ein Auto erkannt wird ‚Üí Ampel schalten
    for result in results:
        if "car" in result.names.values():
            client.publish("ampel", "gruen")
        else:
            client.publish("ampel", "rot")
```

Auf dem **ESP32 oder Raspberry Pi** wird dann ein MQTT-Listener laufen, der die Ampel steuert.  

---

### **Zusammenfassung:**  
‚úÖ Kamera einrichten üé•  
‚úÖ YOLO-Modell nutzen üß†  
‚úÖ Video speichern & nach 14 Tagen l√∂schen üíæ  
‚úÖ Ampel steuern üö¶  

Das ist der komplette Aufbau! üòÉ M√∂chtest du Hilfe bei einem bestimmten Teil?
